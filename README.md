____________________________________________________________________________________

# Project Name
This project is a part of the  **Infraestructura y Arquitectura de TI** course in the Data Science Master, Universidad Icesi, Cali Colombia. 

#### -- Project Status: [Active]

## Contributing Members

**Member 1: [Luisa F. Giraldo](https://github.com/fernandag21)(@slackHandle)** 
**Member 2: [Juan S. Guzman](https://github.com/guzmanjs)(@slackHandle)**

#### Other Members:

|Name     |  Email   | 
|---------|-----------------|
|[Full Name](https://github.com/[github handle])| @johnDoe        |
|[Full Name](https://github.com/[github handle]) |     @janeDoe    |

## Contact
* Feel free to contact the any member of the team with any questions or if you are interested in contributing!


## Project Intro/Objective
The purpose of this project is to build an ETL process using Pentaho Data Integration (PDI) in order to obtain a csv file, performing the process of extraction and transformation of the data available in the relational database BD Ames, in csv files and in MongoDB.


### Methods Used
* Inferential Statistics
* Machine Learning
* Data Visualization
* Predictive Modeling
* etc.

### Technologies
* R 
* Python
* D3
* PostGres, MySql
* Pandas, jupyter
* HTML
* JavaScript
* etc. 

## Project Description
(Provide a more detailed overview of the project.  Talk a bit about your data sources and what questions and hypotheses you are exploring. What specific data analysis/visualization and modeling work are you using to solve the problem? What blockers and challenges are you facing?  Feel free to number or bullet point things here)

## Getting Started
Instructions for contributors
1. Clone this repo (for help see this [tutorial](https://help.github.com/articles/cloning-a-repository/)).
2. Raw Data is being kept [here](Repo folder containing raw data) within this repo.

    *If using offline data mention that and how contributors may obtain the data )*
    
3. Data processing/transformation scripts are being kept [here](Repo folder containing data processing scripts/notebooks)
4. etc...

*If your project is well underway and setup is fairly complicated (ie. requires installation of many packages) create another "setup.md" file and link to it here*  

5. Follow setup [instructions](Link to file)

## Featured Notebooks/Analysis/Deliverables
* [Notebook/Markdown/Slide Deck Title](link)
* [Notebook/Markdown/Slide DeckTitle](link)
* [Blog Post](link)


